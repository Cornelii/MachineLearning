{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "#import tensorflow.contrib.eager as tfe\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 21\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "ckpt_dir_name = 'checkpoints'\n",
    "model_dir_name = 'mnist_basic_seq'\n",
    "\n",
    "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)\n",
    "\n",
    "## TensorBoard\n",
    "log_dir = os.path.join(cur_dir, 'tensorboard', model_dir_name)\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.astype(np.float32) / 255\n",
    "test_x = test_x.astype(np.float32) / 255\n",
    "\n",
    "train_x = np.reshape(train_x, [-1,28*28])\n",
    "test_x = np.reshape(test_x, [-1,28*28])\n",
    "\n",
    "train_y = to_categorical(train_y, 10) ## one-hot encoding\n",
    "test_y = to_categorical(test_y,10)\n",
    "\n",
    "# tf.data.Dataset\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(buffer_size=70000).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 10) (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-80108cb1971a>:6: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "def create_model():\n",
    "    def model(x):\n",
    "        with tf.variable_scope('basic_model_for_mnist', reuse=False):\n",
    "            layer1 = tf.layers.dense(x, 256, activation=tf.nn.sigmoid, name='layer1')\n",
    "            layer2 = tf.layers.dense(layer1, 10, name='layer2')\n",
    "        return layer2\n",
    "    return model\n",
    "\n",
    "def loss_fn(pred, Y):\n",
    "    loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(logits=pred, onehot_labels=Y))\n",
    "    return loss\n",
    "\n",
    "def evaluate(pred, Y):\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred,1), tf.argmax(Y, 1)), tf.float32))\n",
    "    return accuracy\n",
    "\n",
    "pred = create_model()(X)\n",
    "loss = loss_fn(pred, Y)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=0.1)\n",
    "\n",
    "acc = evaluate(pred, Y)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\student\\Git\\MachineLearning\\MachineLearning_basic\\Edwith\\Deep_learning_for_everyone_by_SKim\\checkpoints\\mnist_basic_seq\\mnist_basic_seq.ckpt\n",
      "Restored Variables successfully\n",
      "1# epoch:\n",
      "train data:\n",
      "\t loss:0.2889839035148422 \t accuracy:0.9170333356658618\n",
      "test data:\n",
      "\t accuracy:0.9195000022649765\n",
      "2# epoch:\n",
      "train data:\n",
      "\t loss:0.28778583969920873 \t accuracy:0.9170333351691564\n",
      "3# epoch:\n",
      "train data:\n",
      "\t loss:0.28658168400327366 \t accuracy:0.917550002237161\n",
      "4# epoch:\n",
      "train data:\n",
      "\t loss:0.2854654851680001 \t accuracy:0.917983334461848\n",
      "5# epoch:\n",
      "train data:\n",
      "\t loss:0.2843150143697858 \t accuracy:0.9178500015536945\n",
      "6# epoch:\n",
      "train data:\n",
      "\t loss:0.28325578474750124 \t accuracy:0.9186666695276896\n",
      "7# epoch:\n",
      "train data:\n",
      "\t loss:0.2820936242987712 \t accuracy:0.919066669344902\n",
      "8# epoch:\n",
      "train data:\n",
      "\t loss:0.28104534597446523 \t accuracy:0.9194666683673859\n",
      "9# epoch:\n",
      "train data:\n",
      "\t loss:0.28004473907252153 \t accuracy:0.9197666680812836\n",
      "10# epoch:\n",
      "train data:\n",
      "\t loss:0.2788349267716209 \t accuracy:0.9200500020384789\n",
      "11# epoch:\n",
      "train data:\n",
      "\t loss:0.27798643757899605 \t accuracy:0.9203666683038075\n",
      "test data:\n",
      "\t accuracy:0.9221000021696091\n",
      "12# epoch:\n",
      "train data:\n",
      "\t loss:0.276803046601514 \t accuracy:0.9206666694084803\n",
      "13# epoch:\n",
      "train data:\n",
      "\t loss:0.27587054268767436 \t accuracy:0.92100000222524\n",
      "14# epoch:\n",
      "train data:\n",
      "\t loss:0.27491790082305667 \t accuracy:0.9209166692694029\n",
      "15# epoch:\n",
      "train data:\n",
      "\t loss:0.2737312000244856 \t accuracy:0.9218666676680247\n",
      "16# epoch:\n",
      "train data:\n",
      "\t loss:0.2729099479317665 \t accuracy:0.9218166680137316\n",
      "17# epoch:\n",
      "train data:\n",
      "\t loss:0.27180251949777207 \t accuracy:0.9225166684389114\n",
      "18# epoch:\n",
      "train data:\n",
      "\t loss:0.27088986108700436 \t accuracy:0.9225500029325485\n",
      "19# epoch:\n",
      "train data:\n",
      "\t loss:0.26988013841211794 \t accuracy:0.922733335395654\n",
      "20# epoch:\n",
      "train data:\n",
      "\t loss:0.2689097859834631 \t accuracy:0.9232833344737689\n",
      "21# epoch:\n",
      "train data:\n",
      "\t loss:0.26800216363122065 \t accuracy:0.9235666693250338\n",
      "test data:\n",
      "\t accuracy:0.9254000008106231\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'writer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-06bad85447b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_prefix\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".ckpt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'writer' is not defined"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "train_iterator = train_dataset.make_initializable_iterator()\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "\n",
    "tr_x, tr_y = train_iterator.get_next()\n",
    "ts_x, ts_y = test_iterator.get_next()\n",
    "\n",
    "num_train_iter = train_x.shape[0] // batch_size\n",
    "num_test_iter = test_x.shape[0] // batch_size\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    ## TensorBoard\n",
    "    file_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "    \n",
    "    \n",
    "    # restore variables\n",
    "    try:\n",
    "        saver.restore(sess, checkpoint_prefix+'.ckpt')\n",
    "        print(\"Restored Variables successfully\")\n",
    "    except:\n",
    "        print(\"Failed Restoring Variables\")\n",
    "    \n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(train_iterator.initializer)\n",
    "        \n",
    "        avg_loss = 0\n",
    "        avg_train_acc = 0\n",
    "        avg_test_acc = 0\n",
    "        train_step = 0\n",
    "        test_step = 0\n",
    "        \n",
    "        for _ in range(num_train_iter):\n",
    "            x, y = sess.run([tr_x, tr_y])\n",
    "            _, step_loss, step_acc = sess.run([train, loss, acc], feed_dict={X:x, Y:y})\n",
    "            \n",
    "            avg_loss += step_loss\n",
    "            avg_train_acc += step_acc\n",
    "            train_step += 1\n",
    "        avg_loss = avg_loss / train_step\n",
    "        avg_train_acc = avg_train_acc / train_step\n",
    "        \n",
    "        print(\"{}# epoch:\".format(epoch+1))\n",
    "        print(\"train data:\")\n",
    "        print(\"\\t loss:{} \\t accuracy:{}\".format(avg_loss, avg_train_acc))\n",
    "        \n",
    "        if epoch%10 == 0:\n",
    "            sess.run(test_iterator.initializer)\n",
    "            for _ in range(num_test_iter):\n",
    "                x, y = sess.run([ts_x, ts_y])\n",
    "                step_acc = sess.run(acc, feed_dict={X:x, Y:y})\n",
    "                test_step += 1\n",
    "                avg_test_acc += step_acc\n",
    "            avg_test_acc /= test_step\n",
    "            \n",
    "            print(\"test data:\")\n",
    "            print(\"\\t accuracy:{}\".format(avg_test_acc))\n",
    "            saver.save(sess, checkpoint_prefix+\".ckpt\")\n",
    "    \n",
    "    file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=tensorboard\\mnist_basic_seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
