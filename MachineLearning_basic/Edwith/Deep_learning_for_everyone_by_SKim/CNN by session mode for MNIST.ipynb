{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 21\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "ckpt_dir_name = 'checkpoints'\n",
    "model_dir_name = 'cnn_session_mode'\n",
    "\n",
    "checkpoint_dir = os.path.join(cur_dir, ckpt_dir_name, model_dir_name)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10) (10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_x = train_x.astype(np.float32) / 255\n",
    "test_x = test_x.astype(np.float32) / 255\n",
    "\n",
    "train_x = np.expand_dims(train_x,3)\n",
    "test_X = np.expand_dims(test_x,3)\n",
    "\n",
    "train_y = to_categorical(train_y, 10)\n",
    "test_y = to_categorical(test_y, 10)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(buffer_size=70000).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "\n",
    "num_train_data = train_x.shape[0]\n",
    "num_test_data = test_x.shape[0]\n",
    "\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "        self.Y = tf.placeholder(tf.float32, [None,10])\n",
    "        self.is_training = tf.placeholder(tf.bool, [])\n",
    "    \n",
    "    def create_model(self, reuse=False):\n",
    "        self.model = self._model(self.X, self.is_training, reuse=reuse)\n",
    "        \n",
    "    def _model(self, x, is_training=False, reuse=False):\n",
    "        with tf.variable_scope('model_layers', reuse=reuse):\n",
    "            conv1 = tf.contrib.layers.conv2d(x, 32, 3, padding='SAME', scope=\"conv1\", activation_fn=None)\n",
    "            # (n, 28, 28, 1) => (n, 28, 28,32)\n",
    "            batch1 = tf.contrib.layers.batch_norm(conv1, is_training=is_training, scope=\"batch1\",activation_fn=tf.nn.relu)\n",
    "            pool1 = tf.contrib.layers.max_pool2d(batch1, 2)\n",
    "            # (n, 28, 28, 32) => (n, 14, 14,32)\n",
    "            \n",
    "            conv2 = tf.contrib.layers.conv2d(pool1, 64, 3, padding='SAME',scope='conv2', activation_fn=None)\n",
    "            # (n, 14, 14, 32) => (n, 14, 14, 64)\n",
    "            batch2 = tf.contrib.layers.batch_norm(conv2, is_training=is_training, scope=\"batch2\", activation_fn=tf.nn.relu)\n",
    "            pool2 = tf.contrib.layers.max_pool2d(batch2, 2)\n",
    "            # (n, 14, 14, 64) => (n, 7, 7, 64)\n",
    "            \n",
    "            conv3 = tf.contrib.layers.conv2d(pool2, 128, 3, padding='SAME', scope='conv3', activation_fn=None)\n",
    "            # (n, 7, 7, 64) => (n, 7, 7, 128)\n",
    "            batch3 = tf.contrib.layers.batch_norm(conv3, is_training=is_training, scope='batch3', activation_fn=tf.nn.relu)\n",
    "            \n",
    "            flatten = tf.contrib.layers.flatten(batch3, scope='flatten')\n",
    "            \n",
    "            # fully-connected-layer\n",
    "            fc_layer1 = tf.contrib.layers.fully_connected(flatten, 256, activation_fn=None, scope='fc_layer1')\n",
    "            batch4 = tf.contrib.layers.batch_norm(fc_layer1, is_training=is_training, scope='batch4', activation_fn=tf.nn.relu)\n",
    "            \n",
    "            output = tf.contrib.layers.fully_connected(batch4, 10, activation_fn=None, scope='output_layer')\n",
    "            \n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From c:\\program files\\python35\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "cnn = Model()\n",
    "cnn.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
