{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "training_epochs = 6\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "model_dir_name = 'cnn_eager_mode'\n",
    "\n",
    "checkpoint_dir = os.path.join(cur_dir, 'checkpoints', model_dir_name)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "after preprocessing\n",
      "(60000, 28, 28, 1) (60000, 10) (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)\n",
    "\n",
    "train_x = train_x.astype(np.float32) / 255\n",
    "test_x = test_x.astype(np.float32) / 255\n",
    "\n",
    "train_x = np.expand_dims(train_x, 3)\n",
    "test_x = np.expand_dims(test_x, 3)\n",
    "\n",
    "train_y = to_categorical(train_y, 10)\n",
    "test_y = to_categorical(test_y, 10)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(buffer_size=70000).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(batch_size)\n",
    "print('after preprocessing')\n",
    "print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, padding='SAME', activation='relu')\n",
    "        self.pool1 = keras.layers.MaxPool2D(padding='SAME')\n",
    "        \n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, padding='SAME', activation=None)\n",
    "        self.batch2 = keras.layers.BatchNormalization()\n",
    "        self.relu2 = keras.layers.ReLU()\n",
    "        self.pool2 = keras.layers.MaxPool2D(padding='SAME')\n",
    "        \n",
    "        self.conv3 = keras.layers.Conv2D(128, 3, padding='SAME', activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.dropout1 = keras.layers.Dropout(0.3)\n",
    "        \n",
    "        self.dense_fc = keras.layers.Dense(256, activation=None)\n",
    "        self.batch_fc = keras.layers.BatchNormalization()\n",
    "        self.relu_fc = keras.layers.ReLU()\n",
    "        self.dropout_fc = keras.layers.Dropout(0.3)\n",
    "        \n",
    "        self.output_layer = keras.layers.Dense(10, activation=None)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        net = self.conv1(inputs)\n",
    "        net = self.pool1(net)\n",
    "        \n",
    "        net = self.conv2(net)\n",
    "        net = self.batch2(net)\n",
    "        net = self.relu2(net)\n",
    "        net = self.pool2(net)\n",
    "        \n",
    "        net = self.conv3(net)\n",
    "        net = self.flatten(net)\n",
    "        net = self.dropout1(net)\n",
    "        net = self.dense_fc(net)\n",
    "        net = self.batch_fc(net)\n",
    "        net = self.relu_fc(net)\n",
    "        net = self.dropout_fc(net)\n",
    "        \n",
    "        net = self.output_layer(net)\n",
    "        return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, x, labels):\n",
    "    logits = model(x, training=True)\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=labels))\n",
    "    return loss\n",
    "\n",
    "def grad(model, x, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = loss_fn(model, x, labels)\n",
    "    return tape.gradient(loss, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, epsilon=0.01)\n",
    "\n",
    "def metric(model, x, labels):\n",
    "    logits = model(x, training=False)\n",
    "    pred = tf.equal(tf.argmax(logits,1), tf.argmax(labels,1))\n",
    "    acc = tf.reduce_mean(tf.cast(pred, tf.float32))\n",
    "    return acc\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(cnn=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th Epoch\n",
      "train_avg_loss: 0.029715023934841156\t train_avg_acc: 0.9920313358306885\n",
      "test_avg_acc: 0.9878000020980835\n",
      "2th Epoch\n",
      "train_avg_loss: 0.018695184960961342\t train_avg_acc: 0.9951484203338623\n",
      "3th Epoch\n",
      "train_avg_loss: 0.012028713710606098\t train_avg_acc: 0.9974321722984314\n",
      "4th Epoch\n",
      "train_avg_loss: 0.009232631884515285\t train_avg_acc: 0.9977321624755859\n",
      "5th Epoch\n",
      "train_avg_loss: 0.00614493852481246\t train_avg_acc: 0.9985994696617126\n",
      "6th Epoch\n",
      "train_avg_loss: 0.004174050875008106\t train_avg_acc: 0.9991827607154846\n",
      "test_avg_acc: 0.9894000887870789\n"
     ]
    }
   ],
   "source": [
    "num_train_data = train_x.shape[0]\n",
    "num_test_data = test_x.shape[0]\n",
    "\n",
    "\n",
    "status = checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "status.initialize_or_restore()\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0\n",
    "    avg_train_acc = 0\n",
    "    avg_test_acc = 0\n",
    "    train_step = 0\n",
    "    test_step = 0\n",
    "    \n",
    "    for images, labels in train_dataset:\n",
    "        grads = grad(model, images, labels)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables))\n",
    "        loss = loss_fn(model, images, labels)\n",
    "        acc = metric(model, images, labels)\n",
    "        avg_loss += loss\n",
    "        avg_train_acc += acc\n",
    "        train_step += 1\n",
    "    avg_loss /= train_step\n",
    "    avg_train_acc /= train_step\n",
    "    print(\"{}th Epoch\".format(epoch+1))\n",
    "    print(\"train_avg_loss: {}\\t train_avg_acc: {}\".format(avg_loss, avg_train_acc))\n",
    "    \n",
    "    if (epoch)%5 == 0:\n",
    "        for images, labels in test_dataset:\n",
    "            grads = grad(model, images, labels)\n",
    "            acc = metric(model, images, labels)\n",
    "            avg_test_acc += acc\n",
    "            test_step += 1\n",
    "        avg_test_acc /= test_step\n",
    "        print(\"test_avg_acc: {}\".format(avg_test_acc))\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
